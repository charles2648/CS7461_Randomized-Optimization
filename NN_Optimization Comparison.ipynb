{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dHxgpB8Pjhs3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7462b409-e460-4844-bee6-bff176379eef"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import mlrose_hiive as mlrh\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yA06rd_w7Ydt"
   },
   "source": [
    "The text dataset (depression_dataset_reddit_cleaned) is adopted from kaggle (https://www.kaggle.com/datasets/infamouscoder/depression-reddit-cleaned), which contains texts to classify mental health.\n",
    "\n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "ltwyt7PPh004",
    "outputId": "ab665890-b16a-4ac3-9c97-f0775a6d371b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 13611 rows and 17 columns.\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n0  28395    610.291       208.178117       173.888747      1.197191   \n1  28734    638.018       200.524796       182.734419      1.097356   \n2  29380    624.110       212.826130       175.931143      1.209713   \n3  30008    645.884       210.557999       182.516516      1.153638   \n4  30140    620.134       201.847882       190.279279      1.060798   \n\n   Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n0      0.549812       28715     190.141097  0.763923  0.988856   0.958027   \n1      0.411785       29172     191.272750  0.783968  0.984986   0.887034   \n2      0.562727       29690     193.410904  0.778113  0.989559   0.947849   \n3      0.498616       30724     195.467062  0.782681  0.976696   0.903936   \n4      0.333680       30417     195.896503  0.773098  0.990893   0.984877   \n\n   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  Class  \n0     0.913358      0.007332      0.003147      0.834222      0.998724  SEKER  \n1     0.953861      0.006979      0.003564      0.909851      0.998430  SEKER  \n2     0.908774      0.007244      0.003048      0.825871      0.999066  SEKER  \n3     0.928329      0.007017      0.003215      0.861794      0.994199  SEKER  \n4     0.970516      0.006697      0.003665      0.941900      0.999166  SEKER  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Area</th>\n      <th>Perimeter</th>\n      <th>MajorAxisLength</th>\n      <th>MinorAxisLength</th>\n      <th>AspectRation</th>\n      <th>Eccentricity</th>\n      <th>ConvexArea</th>\n      <th>EquivDiameter</th>\n      <th>Extent</th>\n      <th>Solidity</th>\n      <th>roundness</th>\n      <th>Compactness</th>\n      <th>ShapeFactor1</th>\n      <th>ShapeFactor2</th>\n      <th>ShapeFactor3</th>\n      <th>ShapeFactor4</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>28395</td>\n      <td>610.291</td>\n      <td>208.178117</td>\n      <td>173.888747</td>\n      <td>1.197191</td>\n      <td>0.549812</td>\n      <td>28715</td>\n      <td>190.141097</td>\n      <td>0.763923</td>\n      <td>0.988856</td>\n      <td>0.958027</td>\n      <td>0.913358</td>\n      <td>0.007332</td>\n      <td>0.003147</td>\n      <td>0.834222</td>\n      <td>0.998724</td>\n      <td>SEKER</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28734</td>\n      <td>638.018</td>\n      <td>200.524796</td>\n      <td>182.734419</td>\n      <td>1.097356</td>\n      <td>0.411785</td>\n      <td>29172</td>\n      <td>191.272750</td>\n      <td>0.783968</td>\n      <td>0.984986</td>\n      <td>0.887034</td>\n      <td>0.953861</td>\n      <td>0.006979</td>\n      <td>0.003564</td>\n      <td>0.909851</td>\n      <td>0.998430</td>\n      <td>SEKER</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29380</td>\n      <td>624.110</td>\n      <td>212.826130</td>\n      <td>175.931143</td>\n      <td>1.209713</td>\n      <td>0.562727</td>\n      <td>29690</td>\n      <td>193.410904</td>\n      <td>0.778113</td>\n      <td>0.989559</td>\n      <td>0.947849</td>\n      <td>0.908774</td>\n      <td>0.007244</td>\n      <td>0.003048</td>\n      <td>0.825871</td>\n      <td>0.999066</td>\n      <td>SEKER</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30008</td>\n      <td>645.884</td>\n      <td>210.557999</td>\n      <td>182.516516</td>\n      <td>1.153638</td>\n      <td>0.498616</td>\n      <td>30724</td>\n      <td>195.467062</td>\n      <td>0.782681</td>\n      <td>0.976696</td>\n      <td>0.903936</td>\n      <td>0.928329</td>\n      <td>0.007017</td>\n      <td>0.003215</td>\n      <td>0.861794</td>\n      <td>0.994199</td>\n      <td>SEKER</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>30140</td>\n      <td>620.134</td>\n      <td>201.847882</td>\n      <td>190.279279</td>\n      <td>1.060798</td>\n      <td>0.333680</td>\n      <td>30417</td>\n      <td>195.896503</td>\n      <td>0.773098</td>\n      <td>0.990893</td>\n      <td>0.984877</td>\n      <td>0.970516</td>\n      <td>0.006697</td>\n      <td>0.003665</td>\n      <td>0.941900</td>\n      <td>0.999166</td>\n      <td>SEKER</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load drybean data\n",
    "df_bean = pd.read_excel('Dry_Bean_Dataset.xlsx')\n",
    "print(\"Data has\", len(df_bean), \"rows and\", len(df_bean.columns), \"columns.\")\n",
    "if df_bean.isnull().values.any():\n",
    "    print(\"Warning: Missing Data\")\n",
    "label = df_bean[\"Class\"].unique()\n",
    "df_bean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data Preparation"
   ],
   "metadata": {
    "id": "NwLcmGlq62qo"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNnUG4hBtCOU"
   },
   "source": [
    "## Gradient Descent vs Optimization method\n",
    "\n",
    "In this part, Gradient Descent is compared with randomized hill climbing, simulated annealing and genetic algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxxPl26I4GF0"
   },
   "source": [
    "### Define Helper functions\n",
    "Let's define some helper functions that will be used across all of the models. We define a function that plots the learning curve of an classification model. Additionally, we define functions to output final model scores using an untouched test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import precision_score, accuracy_score, ConfusionMatrixDisplay, roc_auc_score, recall_score, classification_report\n",
    "import timeit\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "def plot_learning_curve(clf, X, y, title=\"Insert Title\"):\n",
    "\n",
    "    n = len(y)\n",
    "    train_mean = [] #model performance score (f1)\n",
    "    cv_mean = []  #model performance score (f1)\n",
    "    fit_mean = [] #model fit/training time\n",
    "    pred_mean = [] #model test/prediction times\n",
    "    train_sizes = (np.linspace(0.1, 1.0, 5)*n).astype('int')\n",
    "\n",
    "    fit_clf = clf.fit(X, y)\n",
    "\n",
    "    for i in train_sizes:\n",
    "        idx = np.random.randint(X.shape[0], size=i)\n",
    "        X_subset = X[idx,:]\n",
    "        y_subset = y[idx]\n",
    "        scores = cross_validate(clf, X_subset, y_subset, cv=5, scoring='f1_weighted', n_jobs=-1, return_train_score=True)\n",
    "\n",
    "        train_mean.append(np.mean(scores['train_score']))\n",
    "        cv_mean.append(np.mean(scores['test_score']))\n",
    "        fit_mean.append(np.mean(scores['fit_time']))\n",
    "        pred_mean.append(np.mean(scores['score_time']))\n",
    "\n",
    "    train_mean = np.array(train_mean)\n",
    "    cv_mean = np.array(cv_mean)\n",
    "    fit_mean = np.array(fit_mean)\n",
    "\n",
    "    plot_LC(train_sizes, train_mean, cv_mean, title)\n",
    "    plot_times(train_sizes, fit_mean, pred_mean, title)\n",
    "    plot_fitness_iteration(fit_clf.fitness_curve, \"{} Fitness Curve\".format(title))\n",
    "\n",
    "\n",
    "\n",
    "def plot_LC(train_sizes, train_mean, cv_mean, title):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(\"Learning Curve: \"+ title)\n",
    "    plt.xlabel(\"Training Examples\")\n",
    "    plt.ylabel(\"Model Accuracy Score\")\n",
    "    plt.plot(train_sizes, train_mean, 'o-', color=\"b\", label=\"Training Score\")\n",
    "    plt.plot(train_sizes, cv_mean, 'o-', color=\"r\", label=\"Cross-Validation Score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_times(train_sizes, fit_mean, pred_mean, title):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(\"Modeling Time: \"+ title)\n",
    "    plt.xlabel(\"Training Examples\")\n",
    "    plt.ylabel(\"Training Time (s)\")\n",
    "    plt.plot(train_sizes, fit_mean, 'o-', color=\"b\", label=\"Training Time (s)\")\n",
    "    plt.plot(train_sizes, pred_mean, 'o-', color=\"r\", label=\"Prediction Time (s)\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_fitness_iteration(curve, title, max_fitness=None):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Fitness')\n",
    "    plt.title(title)\n",
    "    length = len(curve)\n",
    "    plt.plot(range(length), curve, label='Fitness', lw=2)\n",
    "\n",
    "    if max_fitness:\n",
    "        plt.plot(range(length), [max_fitness] * length, label=\"Max Fitness\", lw=1, color=\"darkorange\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def final_classifier_evaluation(clf,X_train, X_test, y_train, y_test):\n",
    "\n",
    "    start_time = timeit.default_timer()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end_time = timeit.default_timer()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "\n",
    "    start_time = timeit.default_timer()\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    end_time = timeit.default_timer()\n",
    "    pred_time = end_time - start_time\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "    print(\"Model Evaluation Metrics Using Test Dataset\")\n",
    "    print(\"*****************************************************\")\n",
    "    print(\"Model Training Time (s):   \"+\"{:.5f}\".format(training_time))\n",
    "    print(\"Model Prediction Time (s): \"+\"{:.5f}\\n\".format(pred_time))\n",
    "    print(\"Accuracy:  \"+\"{:.2f}\".format(accuracy))\n",
    "    print(\"Training Classification report\", classification_report(y_train, y_pred_train))\n",
    "    print(\"*****************************************************\")\n",
    "    print(\"Testing Classification report\", classification_report(y_test, y_pred_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kevr6Y6IuaJT"
   },
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# turn categorical class type into numerical values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_bean.drop(['Class'], axis=1)\n",
    "y = df_bean.Class\n",
    "\n",
    "# Data Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), y, test_size = 0.2, random_state = 100, stratify=y)\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = pd.get_dummies(y_train.values.ravel()).values\n",
    "y_test = pd.get_dummies(y_test.values.ravel()).values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "nn_model = mlrh.NeuralNetwork(hidden_nodes = [3],\n",
    "                                activation = 'relu',\n",
    "                                algorithm = 'gradient_descent',\n",
    "                                max_iters = 5000,\n",
    "                                bias = True,\n",
    "                                is_classifier = True,\n",
    "                                learning_rate = 0.1,\n",
    "                                early_stopping = True,\n",
    "                                clip_max = 1.0,\n",
    "                                max_attempts =100,\n",
    "                                curve=True,\n",
    "                                random_state = 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pNnjz2dTrAs"
   },
   "source": [
    "The final section for neural network will plot the loss curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#plot_learning_curve(nn_model, X_train, y_train, title=\"Gradient Descent\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_classifier_evaluation(nn_model, X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkmwJVytUeIS"
   },
   "source": [
    "### Simulated Annealing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nn_model = mlrh.NeuralNetwork(hidden_nodes=[3],\n",
    "                                activation='relu',\n",
    "                                algorithm='simulated_annealing',\n",
    "                                schedule=mlrh.GeomDecay(5),\n",
    "                                max_iters=5000,\n",
    "                                max_attempts=100,\n",
    "                                bias=True,\n",
    "                                is_classifier=True,\n",
    "                                learning_rate=0.1,\n",
    "                                early_stopping=True,\n",
    "                                clip_max=1.0,\n",
    "                                curve=True,\n",
    "                                random_state=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#plot_learning_curve(nn_model, X_train, y_train, title=\"Simulated Annealing\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_classifier_evaluation(nn_model, X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4d3ok_7blc4"
   },
   "source": [
    "### Randomized Hill Climbing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "go0b0qAkdM5t"
   },
   "outputs": [],
   "source": [
    "nn_model = mlrh.NeuralNetwork(hidden_nodes=[3],\n",
    "                                activation='relu',\n",
    "                                algorithm='random_hill_climb',\n",
    "                                max_iters=5000,\n",
    "                                max_attempts=100,\n",
    "                                bias=True,\n",
    "                                restarts=20,\n",
    "                                is_classifier=True,\n",
    "                                learning_rate=0.1,\n",
    "                                early_stopping=True,\n",
    "                                clip_max=1.0,\n",
    "                                curve=True,\n",
    "                                random_state=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#plot_learning_curve(nn_model, X_train, y_train, title=\"Randomized Hill Climbing\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Metrics Using Test Dataset\n",
      "*****************************************************\n",
      "Model Training Time (s):   692.34773\n",
      "Model Prediction Time (s): 0.00040\n",
      "\n",
      "Accuracy:  0.81\n",
      "Training Classification report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.16      0.26      1057\n",
      "           1       0.41      0.99      0.58       418\n",
      "           2       0.81      0.89      0.85      1304\n",
      "           3       0.82      0.93      0.87      2837\n",
      "           4       0.84      0.94      0.88      1542\n",
      "           5       0.92      0.92      0.92      1621\n",
      "           6       0.84      0.65      0.73      2109\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10888\n",
      "   macro avg       0.78      0.78      0.73     10888\n",
      "weighted avg       0.83      0.80      0.78     10888\n",
      " samples avg       0.80      0.80      0.80     10888\n",
      "\n",
      "*****************************************************\n",
      "Testing Classification report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.15      0.25       265\n",
      "           1       0.39      0.99      0.56       104\n",
      "           2       0.82      0.91      0.86       326\n",
      "           3       0.84      0.94      0.89       709\n",
      "           4       0.85      0.94      0.89       386\n",
      "           5       0.91      0.92      0.91       406\n",
      "           6       0.86      0.67      0.75       527\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      2723\n",
      "   macro avg       0.78      0.79      0.73      2723\n",
      "weighted avg       0.83      0.81      0.79      2723\n",
      " samples avg       0.81      0.81      0.81      2723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_classifier_evaluation(nn_model, X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-pbyKhee6pz"
   },
   "source": [
    "###  Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LioDo2JWnkDE"
   },
   "outputs": [],
   "source": [
    "nn_model = mlrh.NeuralNetwork(hidden_nodes=[3],\n",
    "                              activation='relu',\n",
    "                              algorithm='genetic_alg',\n",
    "                              max_iters=5000,\n",
    "                              max_attempts=100,\n",
    "                              bias=True,\n",
    "                              is_classifier=True,\n",
    "                              learning_rate=0.01,\n",
    "                              mutation_prob=0.1,\n",
    "                              pop_size=1000,\n",
    "                              early_stopping=True,\n",
    "                              clip_max=1.0,\n",
    "                              curve=True,\n",
    "                              random_state=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#plot_learning_curve(nn_model, X_train, y_train, title=\"Genetic Algorithm\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_classifier_evaluation(nn_model, X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
